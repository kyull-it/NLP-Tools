{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bb9e70-5a29-4cc0-915b-473e95362460",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "https://huggingface.co/tasks/text-generation\n",
    "https://huggingface.co/docs/transformers/installation#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcaed9c-4a72-4b0d-a18c-43ed940e427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd60fd6e-38b1-4099-80a4-d46c2d14ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bce78dd67d433c9cdc7428018121e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbeaeccf0e614defbf44d99c6b69d25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe8c9706927450aa4549a999721247c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a53f80b6810447a9cb18498b4904583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3747a79a208947139a922344b65ebd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language modeler.\\n\\nDo you know why you need to do this work\\n\\nI know this question does not seem\"},\n",
       " {'generated_text': \"Hello, I'm a language modeler. I've done a lot of research, studying languages like Esperanto, Java, C as a programming language\"},\n",
       " {'generated_text': \"Hello, I'm a language modeler â€“ I take care of all that is necessary to create a language. I try to avoid any hard decisions like\"}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(\"Hello, I'm a language model\", max_length = 30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bd68e06-ed08-40ef-84d5-f8a565b1a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is 42? Why does it bother me when there is \"42\" in another letter? When the original sentence says \"We are 42\", then'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"What is 42?\", max_length = 30, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c8cde0-612f-4cc6-88b8-df65f4e08840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello, Nice to meet you. Your name is Ira. I was wondering if I could give you a moment of my greetings. Oh,'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Hello, Nice to meet you.\", max_length = 30, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61289922-0af8-4f57-b8d1-1ca7ed44e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is 42?'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2text_generator = pipeline(\"text2text-generation\")\n",
    "text2text_generator(\"What is 42?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67fe9391-28d2-4227-b7b8-604b173e588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 testflask.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
