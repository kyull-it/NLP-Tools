{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fcfacd-d782-424d-9a5f-e1a1d2977e0c",
   "metadata": {},
   "source": [
    "# Word Clustering using Spacy\n",
    " - dataset : label of google open image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19944150-9ce0-4175-bbe5-1da036ff1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-word-similarity-using-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df8c27b-9ade-4ad6-8505-37a83b3983bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nd-ygr/anaconda3/envs/test-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-09-26 13:03:54.255476: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-26 13:03:55.372431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-26 13:03:55.373396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-26 13:03:55.373593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/usage\n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68dd30de-4705-489f-9db2-f7e2a3f222f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter two space-separated words\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " interest summer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interest True 48.548546 False\n",
      "summer True 46.243664 False\n",
      "Similarity: 0.18833285570144653\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "print(\"Enter two space-separated words\")\n",
    "words = input()\n",
    "  \n",
    "tokens = nlp(words)\n",
    "  \n",
    "for token in tokens:\n",
    "    # Printing the following attributes of each token.\n",
    "    # text: the word string, has_vector: if it contains\n",
    "    # a vector representation in the model, \n",
    "    # vector_norm: the algebraic norm of the vector,\n",
    "    # is_oov: if the word is out of vocabulary.\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n",
    "\n",
    "\n",
    "token1, token2 = tokens[0], tokens[1]\n",
    "sim = token1.similarity(token2)\n",
    "print(\"Similarity:\", sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21290962-fd67-44bb-807b-aee6d008e91e",
   "metadata": {},
   "source": [
    "### class_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "916b3b8b-ca0f-4dcb-8716-9429c63d7983",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_string = \"\"\"Interest\n",
    "Habit\n",
    "Fun\n",
    "Meme\n",
    "Book\n",
    "Story\n",
    "Education\n",
    "Networking\n",
    "Advice\n",
    "Discussion\n",
    "Dating\n",
    "Religion\n",
    "Health\n",
    "Food\n",
    "Game\n",
    "Sport\n",
    "Music\n",
    "Art\n",
    "Beauty\n",
    "Fashion\n",
    "Movie\n",
    "Entertainment\n",
    "Influencer\n",
    "History\n",
    "Animal\n",
    "Nature\n",
    "Science\n",
    "Technology\n",
    "Economy\n",
    "Politics\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4adcd160-f9b5-4b72-a43c-92388b1c74e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Interest': None, 'Habit': None, 'Fun': None, 'Meme': None, 'Book': None, 'Story': None, 'Education': None, 'Networking': None, 'Advice': None, 'Discussion': None, 'Dating': None, 'Religion': None, 'Health': None, 'Food': None, 'Game': None, 'Sport': None, 'Music': None, 'Art': None, 'Beauty': None, 'Fashion': None, 'Movie': None, 'Entertainment': None, 'Influencer': None, 'History': None, 'Animal': None, 'Nature': None, 'Science': None, 'Technology': None, 'Economy': None, 'Politics': None}\n"
     ]
    }
   ],
   "source": [
    "class_list = []\n",
    "for s in class_string.split(\"\\n\"):\n",
    "    class_list.append(s)\n",
    "\n",
    "# word_dict = {c : 0 for c in class_list}\n",
    "word_dict = dict.fromkeys(class_list)\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d4ad796-f696-4aeb-b976-05a9d9b74eb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test to put list in dict value\n",
    "# https://www.geeksforgeeks.org/appending-to-list-in-python-dictionary/\n",
    "\n",
    "# lst = []\n",
    "# lst.append(\"encouragement\")\n",
    "# word_dict[\"Interest\"] = lst\n",
    "# word_dict[\"Interest\"].append(\"Studying English\")\n",
    "\n",
    "\n",
    "# Test to put list in list  (multi-dimensional)\n",
    "# list = []\n",
    "# list2 = [\"zero\", \"one\", \"two\"]\n",
    "# for i in range(10):\n",
    "#     if i % 2 == 0:\n",
    "#         list.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "545b438a-24bd-4dd5-96ca-f33506313d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DisplayName', \"Sprenger's tulip\", 'Vinegret', 'Dabu-dabu', 'Pistachio ice cream', 'Woku', 'Pastila', 'Burasa', 'Summer snowflake', 'Isle of man tt']\n"
     ]
    }
   ],
   "source": [
    "# Load the language model (large)\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Load the label list of google open dataset\n",
    "file = open('/media/nd-ygr/Data/Image/google/dataset/v6/csv/full/oidv6-class-descriptions.csv', 'r', encoding = 'utf-8')\n",
    "\n",
    "label_list = []\n",
    "exception_list = []\n",
    "for line in file:    \n",
    "    label_list.append(line.split(',')[1].strip())    \n",
    "# print(label_list[0:10])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366388e-4116-4381-be1a-fc0b2eb0b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1 위에서 띄워쓰기 있는거, 기호 있는거, 숫자 있는 label은 예외list로 append하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ae4a5-2f9e-4885-8c0a-ddcb79271918",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2 word_dict.keys와 label_list의 similarity 계산 -> list생성 -> 그 중에 제일 큰 similarity & 0.5이상인 key의 value(list)에 label쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e8ba1-5d49-41d9-adfc-b46c19ff01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3 결과 보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
